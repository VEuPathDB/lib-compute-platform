= Development / Design Notes
:toc:


== TODO

* Job inputs and outputs. +
  These are per service, so we need some way to determine/know what those
  inputs and outputs are. +
  The inputs are less of a problem than the outputs (unless the service wants
  to persist the inputs?)
** As part of the service configuration, they have to be registered?
** Provide methods/hooks to be implemented that choose the files?
* Services may have their own queue setups.  For example, eda-compute will have
  at least 2 queues (6 channels), but other services may only want one or may
  want more.  Specifically in the case of eda-compute, the queue will be
  determined by the plugin, but how would other services decide things like
  this?
** Queue callbacks... These have to be configured per queue unless... well we
   could provide default callbacks and have hook points to perform custom logic
   on success/fail?


== Configuration

TODO!


== Workflows


=== Job Submission Request

image::graphs/job-submission-request.png[]


=== Job Status Request

image::graphs/job-status-request.png[]


=== Service Startup


=== Cache Pruning

image::graphs/cache-pruning.png[]



== Workspaces


=== S3


==== Flags & Markers

`.complete`::
Flag object whose presence indicates that the job represented by the containing
workspace has finished successfully.
+
This flag should not coexist with any other flag objects.

`.expired`::
Flag object whose presence indicates that the job represented by the containing
workspace has expired.
+
If this flag exists, no other workspace objects should exist.

`.failed`::
Flag object whose presence indicates that the job represented by the containing
workspace has finished unsuccessfully.
+
This flag should not coexist with any other flag objects.

`.in-progress`::
Flag object whose presence indicates that the job represented by the containing
workspace is currently running.
+
This flag should not coexist with any other flag objects.

`.queued`::
Flag object whose presence indicates that the job represented by the containing
workspace is currently queued.
+
This flag should not coexist with any other flag objects (but will coexist with
the `.last-accessed` marker object).


==== Job Outputs

TODO!


=== Local Scratch Workspace


==== Inputs & Outputs

TODO!

== Components

=== Service

=== RabbitMQ

=== PostgreSQL

==== Debug Credentials

TODO: Document debug user.

=== S3


== Notes & Thoughts

Unordered development notes.

=== Thoughts

* A failed job should not expire.  It should stay failed until manually cleared.
* Each campus should only prune jobs that they "own".
* Job executor provider/factory.  Need some hook to get a job executor when we
  pop a job from the queue.
* Need to be able to have an arbitrary number of queues.
** How do we determine what queue a job goes to?  If multiple queues are baked
   into the platform itself we need some sort of identifier for each queue.  It
   will have to be part of the platform configuration.
* Platform configuration?
** Should this be a config file?  Should it be programmatic?  May need to be
   statically available.

=== Queries

* Insert new job
* Update job status
** Update from queued to grabbed
** Update from grabbed to finished (failed or complete)
** Update from grabbed to queued (dead job)
** Update from finished to expired (except failed stays in failed status)
* Get job status
* Get job queue position

=== Volumes

* postgres

